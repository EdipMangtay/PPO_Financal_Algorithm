# PPO_Financal_Algorithm - KapsamlÄ± Proje DokÃ¼mantasyonu

## ðŸ“‹ Ä°Ã§indekiler

1. [Proje Genel BakÄ±ÅŸ](#1-proje-genel-bakÄ±ÅŸ)
2. [KlasÃ¶r YapÄ±sÄ± ve GÃ¶revleri](#2-klasÃ¶r-yapÄ±sÄ±-ve-gÃ¶revleri)
3. [Data Flow DiyagramÄ±](#3-data-flow-diyagramÄ±)
4. [Model Mimarisi](#4-model-mimarisi)
5. [Training Pipeline](#5-training-pipeline)
6. [Ã–nemli Dosyalar](#6-Ã¶nemli-dosyalar-ve-ne-zaman-deÄŸiÅŸtirilmeli)
7. [MÃ¼hendislik Ã–nerileri](#7-mÃ¼hendislik-perspektifinden-Ã¶neriler)
8. [Ã‡alÄ±ÅŸtÄ±rma KomutlarÄ±](#8-Ã§alÄ±ÅŸtÄ±rma-komutlarÄ±)
9. [Sorun Giderme](#9-sorun-giderme-iÃ§in-bakÄ±lacak-yerler)
10. [SonuÃ§](#10-sonuÃ§)

---

## 1. PROJE GENEL BAKIÅž

Bu proje, **kripto para ticareti iÃ§in bir Deep Learning tabanlÄ± trading bot** sistemidir. Ä°ki ana model kullanÄ±r:
- **TFT (Temporal Fusion Transformer)**: Fiyat tahmini iÃ§in
- **PPO (Proximal Policy Optimization)**: Trading kararlarÄ± iÃ§in

### Ana Pipeline AkÄ±ÅŸÄ±:
```
Veri Ä°ndirme â†’ Feature Engineering â†’ HPO (Optuna) â†’ Model Training â†’ Backtest â†’ Live Trading
```

### Teknoloji Stack:
- **Deep Learning**: PyTorch, pytorch-forecasting
- **Reinforcement Learning**: stable-baselines3, sb3-contrib
- **Hyperparameter Optimization**: Optuna
- **Data Processing**: pandas, numpy
- **Exchange Integration**: ccxt (Binance)

---

## 2. KLASÃ–R YAPISI VE GÃ–REVLERÄ°

### ðŸ“ **`config/`** - KonfigÃ¼rasyon DosyalarÄ±

TÃ¼m sistem parametreleri YAML formatÄ±nda merkezi olarak yÃ¶netilir.

- **`train.yaml`**: Training parametreleri
  - `date_range`: Veri tarih aralÄ±ÄŸÄ± (start, end)
  - `batch_size`: Her timeframe iÃ§in batch size
  - `learning_rate`: Learning rate per timeframe
  - `epochs`: Training epoch sayÄ±sÄ±
  - `device`: "cuda" veya "cpu"
  - `mixed_precision`: "bf16", "fp16", veya "fp32"
  - `hpo`: Optuna HPO ayarlarÄ± (n_trials, timeout_minutes, n_jobs)
  - `backtest`: Backtest parametreleri (fee_rate, slippage, position_sizing)

- **`features.yaml`**: Feature engineering konfigÃ¼rasyonu
  - `features_common`: TÃ¼m timeframe'ler iÃ§in ortak feature'lar
  - `features_by_timeframe`: Timeframe-specific feature'lar
  - `feature_params`: Feature parametreleri (RSI period, MACD fast/slow, etc.)
  - `target`: Target konfigÃ¼rasyonu (forward_return, horizon_bars)

- **`paths.yaml`**: TÃ¼m dosya yollarÄ±
  - `data_dir`: Ham veri klasÃ¶rÃ¼
  - `cache_dir`: Feature cache klasÃ¶rÃ¼
  - `artifacts_dir`: Model ve sonuÃ§lar klasÃ¶rÃ¼
  - `ckpt_dir`: Checkpoint klasÃ¶rÃ¼
  - `logs_dir`: Log dosyalarÄ± klasÃ¶rÃ¼

**Neden Ã¶nemli?** TÃ¼m hyperparameter'lar ve path'ler tek yerden yÃ¶netilir. YAML formatÄ± sayesinde kod deÄŸiÅŸikliÄŸi olmadan ayarlar deÄŸiÅŸtirilebilir.

### ðŸ“ **`data/`** - Veri YÃ¶netimi

- **`loader_new.py`**: Parquet dosyalarÄ±ndan veri yÃ¼kleme
  - `load_raw()`: Ham OHLCV verisini yÃ¼kle
  - `load_or_resample()`: Target timeframe iÃ§in veri yÃ¼kle, yoksa resample et
  
- **`resample.py`**: Timeframe dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (15m â†’ 1h â†’ 4h)
  - OHLCV kurallarÄ±na gÃ¶re resampling:
    - Open: Ä°lk open
    - High: Maximum high
    - Low: Minimum low
    - Close: Son close
    - Volume: Toplam volume

- **`validators.py`**: Veri kalite kontrolÃ¼
  - Schema validation (required columns, dtypes)
  - Timestamp validation (sorted, unique)
  - Timeframe spacing validation
  - NaN/Inf detection ve temizleme
  - Lookahead leakage kontrolÃ¼

- **`cache.py`**: Feature cache mekanizmasÄ±
  - Feature hash hesaplama
  - Dataset hash hesaplama
  - Cache'den yÃ¼kleme/kaydetme
  - AynÄ± veri iÃ§in tekrar hesaplama Ã¶nleme

- **`raw/`**: Ham OHLCV verileri
  - Parquet formatÄ±nda: `BTC_USDT_15m.parquet`, `BTC_USDT_1h.parquet`, etc.
  - Her dosya: timestamp, open, high, low, close, volume kolonlarÄ± iÃ§erir

**Data Flow:**
```
raw/ â†’ loader_new.py â†’ validators.py â†’ resample.py (gerekirse) â†’ features/
```

### ðŸ“ **`features/`** - Feature Engineering

- **`build_features.py`**: Teknik indikatÃ¶rlerin hesaplanmasÄ±
  - **RSI (Relative Strength Index)**: Momentum gÃ¶stergesi (default period: 14)
  - **MACD**: Trend gÃ¶stergesi (fast: 12, slow: 26, signal: 9)
  - **ATR (Average True Range)**: Volatilite gÃ¶stergesi (period: 14)
  - **Bollinger Bands**: Volatilite bantlarÄ± (period: 20, std: 2.0)
  - **Volume MA**: Volume moving average (period: 20)
  - **Target**: Forward return (12 bar sonrasÄ± fiyat deÄŸiÅŸimi)
    - `target = (future_close - current_close) / current_close`

**Ã–nemli:** Her feature'Ä±n parametreleri `config/features.yaml`'dan okunur. Bu sayede hyperparameter tuning yapÄ±labilir.

### ðŸ“ **`models/`** - Model Mimarileri

- **`tft.py`**: Temporal Fusion Transformer modeli
  - **Encoder**: 60 bar geÃ§miÅŸ veri (lookback window)
  - **Decoder**: 12 bar gelecek tahmin (prediction horizon)
  - **Output**: 
    - Quantile mode: 7 quantile (0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98)
    - Regression mode: 1 output (nokta tahmin)
  - **Context Features**: BTC dominance, USDT dominance gibi makro gÃ¶stergeler
  - **Architecture**:
    - Hidden size: 128 (HPO ile optimize edilir)
    - Attention heads: 4
    - Dropout: 0.1 (HPO ile optimize edilir)
    - LSTM encoder/decoder
    - Temporal attention mechanism

- **`ppo.py`**: PPO Agent (Reinforcement Learning)
  - **Policy**: RecurrentPPO (LSTM-based)
  - **Observation Space**: 
    - TFT confidence (0-1)
    - ATR (volatilite)
    - PnL state (current profit/loss)
    - Position info (current position, size, leverage)
  - **Action Space**: Continuous [-1, 1]
    - Action > 0.3 â†’ LONG
    - Action < -0.3 â†’ SHORT
    - -0.3 â‰¤ Action â‰¤ 0.3 â†’ FLAT (Cash)
  - **Reward**: Portfolio return (risk-adjusted)
  - **Hyperparameters**:
    - Learning rate: 3e-4
    - N steps: 4096
    - Batch size: 256
    - N epochs: 10
    - Gamma: 0.99 (discount factor)
    - GAE lambda: 0.95

- **`tft_ensemble.py`**: 3 timeframe (15m, 1h, 4h) iÃ§in ensemble model
  - Her timeframe iÃ§in ayrÄ± TFT modeli
  - Ensemble prediction: Weighted average of predictions

**Model Contract:** `utils/model_contracts.py` dosyasÄ± output/target/loss uyumunu garanti eder. Bu kritik bir dosyadÄ±r - model deÄŸiÅŸikliklerinde mutlaka kontrol edilmelidir.

### ðŸ“ **`training/`** - Training Pipeline

- **`train_one.py`**: Tek timeframe iÃ§in training pipeline
  - Data loading â†’ Feature building â†’ Split â†’ Dataset creation â†’ Training
  - Cache mekanizmasÄ± ile feature engineering hÄ±zlandÄ±rma
  - Time-based split (shuffle YOK - lookahead bias Ã¶nleme)

- **`train_final.py`**: HPO sonrasÄ± best params ile final training
  - Best hyperparameters ile full training
  - Train+Val birleÅŸtirilerek final model eÄŸitimi
  - Model checkpointing

- **`trainer.py`**: Robust training wrapper
  - **OOM (Out of Memory) handling**: Batch size otomatik azaltma
  - **NaN detection ve recovery**: NaN loss durumunda batch skip
  - **Mixed precision support**: bf16/fp16/fp32
  - **Gradient clipping**: Gradient explosion Ã¶nleme
  - **Early stopping**: Validation loss'a gÃ¶re erken durdurma
  - **Checkpointing**: Best model kaydetme

**Training Flow:**
```
train_one.py â†’ TFTModel.create_dataset() â†’ TFTModel.build_model() â†’ train_with_early_stopping()
```

### ðŸ“ **`hpo/`** - Hyperparameter Optimization

- **`optuna_search.py`**: Optuna ile HPO
  - **Search Space:**
    - `lr`: 1e-5 to 5e-3 (log scale)
    - `batch_size`: [32, 64, 128] (categorical)
    - `dropout`: 0.0 to 0.5 (uniform)
    - `hidden_size`: [64, 128, 256, 512] (categorical)
    - `weight_decay`: 1e-8 to 1e-2 (log scale)
  - **Objective**: Validation loss'u minimize et (negative MAE)
  - **Pruning**: MedianPruner (kÃ¶tÃ¼ trial'larÄ± erken durdur)
  - **Storage**: SQLite database (`optuna.db`)
  - **Sampler**: TPESampler (Tree-structured Parzen Estimator)
  - **Parallelization**: n_jobs parametresi ile (default: 1, sequential)

**HPO Flow:**
```
optuna_search.py â†’ objective() â†’ TFTModel.train() â†’ Validation loss â†’ Optuna study
```

### ðŸ“ **`scripts/`** - Ana Ã‡alÄ±ÅŸtÄ±rma Scriptleri

- **`run_btc_pipeline.py`**: **ANA PIPELINE** (ÅŸu an kullandÄ±ÄŸÄ±nÄ±z)
  - **Phase 1**: Sequential HPO (her timeframe iÃ§in sÄ±rayla)
    - Preflight checks
    - Data loading
    - Feature building
    - Data split
    - Optuna HPO
  - **Phase 2**: Parallel training (best params ile)
    - Final model training
    - Test set evaluation
    - Backtest
  - **Output**: `artifacts/{run_id}/{timeframe}/` altÄ±nda:
    - `optuna.db`: Optuna study database
    - `optuna_best.json`: Best hyperparameters
    - `hpo_summary.json`: HPO Ã¶zeti
    - `model.pt`: Trained model checkpoint
    - `metrics_test.json`: Test set metrikleri
    - `backtest_metrics.json`: Backtest sonuÃ§larÄ±
    - `run_{timeframe}.log`: Log dosyasÄ±

- **`preflight.py`**: Pre-training validation
  - Environment check (CUDA, packages, Python version)
  - Disk space check (minimum 1 GB)
  - Data validation (schema, timestamps, NaN/Inf)
  - Model forward pass sanity check (kÃ¼Ã§Ã¼k batch ile test)

- **`download_data.py`**: Binance'den veri indirme
  - ccxt kÃ¼tÃ¼phanesi ile Binance Futures API
  - 15m, 1h, 4h timeframe'ler iÃ§in veri indirme
  - Parquet formatÄ±nda kaydetme

- **`verify_env.py`**: PyTorch/CUDA kurulum kontrolÃ¼
  - PyTorch version
  - CUDA availability
  - GPU device name ve capability
  - Compute capability kontrolÃ¼ (sm_120 iÃ§in RTX 5070/5080)

### ðŸ“ **`backtest/`** - Backtesting

- **`engine.py`**: Event-driven backtest engine
  - **Position Management**: LONG/SHORT/FLAT
  - **Fee Calculation**: 
    - Taker fee: 0.04% (Binance default)
    - Slippage: 0.05% (realistic for crypto)
  - **Position Sizing**: 
    - Fixed: Sabit yÃ¼zde (default: 10%)
    - Kelly: Kelly Criterion (fractional)
  - **Metrics**: 
    - Sharpe Ratio (annualized)
    - Sortino Ratio (downside deviation)
    - Max Drawdown
    - Win Rate
    - Profit Factor
    - Total Return, CAGR

- **`plots.py`**: Equity curve visualization
  - Matplotlib ile equity curve Ã§izimi
  - Drawdown grafiÄŸi
  - Trade distribution

- **`backtest.py`**: Test set Ã¼zerinde backtest Ã§alÄ±ÅŸtÄ±rma
  - Model predictions â†’ Signals â†’ Backtest engine
  - Signal threshold: 1% predicted return (configurable)

### ðŸ“ **`evaluation/`** - Model Evaluation

- **`metrics.py`**: Regression ve classification metrikleri
  - **Regression**: MAE, RMSE, MAPE, RÂ²
  - **Classification**: Accuracy, Precision, Recall, F1, AUC
  - Safe handling: NaN/Inf deÄŸerleri iÃ§in gÃ¼venli hesaplama

### ðŸ“ **`utils/`** - YardÄ±mcÄ± Fonksiyonlar

- **`device.py`**: GPU/CPU detection ve device management
  - Auto-detect GPU
  - Device mismatch detection
  - Recursive device transfer (dict, tuple, list support)

- **`model_contracts.py`**: **KRÄ°TÄ°K** - Model output/target/loss uyumunu garanti eder
  - Task mode inference (regression/quantile/classification)
  - Shape validation
  - Loss computation (canonical path)
  - Prediction/target extraction

- **`io.py`**: YAML/JSON file I/O
  - `load_yaml()`: YAML dosyasÄ± yÃ¼kleme
  - `save_json()`: JSON dosyasÄ± kaydetme
  - `load_json()`: JSON dosyasÄ± yÃ¼kleme

- **`logging.py`**: Logging setup
  - File ve console logging
  - Timeframe-specific log dosyalarÄ±

- **`seed.py`**: Reproducibility iÃ§in seed management
  - Global seed setting (numpy, torch, random, etc.)
  - Seed info logging

### ðŸ“ **`artifacts/`** - Ã‡Ä±ktÄ±lar

Her run iÃ§in `artifacts/{run_id}/{timeframe}/` altÄ±nda:

- `optuna.db`: Optuna study database (SQLite)
  - TÃ¼m trial'larÄ±n kaydÄ±
  - Optuna dashboard ile gÃ¶rselleÅŸtirilebilir
  
- `optuna_best.json`: Best hyperparameters
  ```json
  {
    "best_params": {
      "lr": 0.001,
      "batch_size": 128,
      "dropout": 0.1,
      "hidden_size": 256,
      "weight_decay": 1e-5
    },
    "best_value": -0.0234,
    "n_trials": 100,
    "n_complete": 87,
    "n_pruned": 12,
    "n_failed": 1
  }
  ```

- `hpo_summary.json`: HPO Ã¶zeti
  - Train/val/test sizes
  - Best params
  - HPO duration

- `model.pt`: Trained model checkpoint
  - Model state dict
  - Optimizer state dict
  - Training history
  - Metadata

- `metrics_test.json`: Test set metrikleri
  - MAE, RMSE, MAPE, RÂ²

- `backtest_metrics.json`: Backtest sonuÃ§larÄ±
  - Total return, Sharpe, Sortino, Max DD
  - Win rate, Profit factor
  - Trade statistics

- `run_{timeframe}.log`: Log dosyasÄ±
  - TÃ¼m training log'larÄ±
  - Error messages
  - Warning messages

### ðŸ“ **`signals/`** - Trading Signals

- **`signal_base.py`**: Signal generator interface
  - Abstract base class
  - `load_model()`: Model yÃ¼kleme
  - `predict_proba()`: Probability tahmini
  - `to_signal()`: Probability â†’ Signal dÃ¶nÃ¼ÅŸÃ¼mÃ¼

- **`signal_15m.py`, `signal_1h.py`, `signal_4h.py`**: Timeframe-specific signal generators
  - Her timeframe iÃ§in Ã¶zel signal logic
  - Threshold-based signal generation

---

## 3. DATA FLOW DÄ°YAGRAMI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Binance API    â”‚
â”‚  (ccxt)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/raw/      â”‚
â”‚  *.parquet      â”‚
â”‚  (OHLCV)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ loader_new.py   â”‚
â”‚ - load_or_resample()
â”‚ - Date filtering
â”‚ - Resampling (if needed)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ validators.py   â”‚
â”‚ - Schema check
â”‚ - Timestamp check
â”‚ - NaN/Inf check
â”‚ - Timeframe spacing
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ build_features.pyâ”‚
â”‚ - RSI, MACD, ATR
â”‚ - Bollinger Bands
â”‚ - Volume MA
â”‚ - Target: forward_return
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ split_time_seriesâ”‚
â”‚ - Train: 70%
â”‚ - Val: 15%
â”‚ - Test: 15%
â”‚ (Time-based, no shuffle)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TimeSeriesDataSetâ”‚
â”‚ (pytorch-forecasting)
â”‚ - Encoder: 60 bars
â”‚ - Decoder: 12 bars
â”‚ - Group by: coin
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TFTModel.train()â”‚
â”‚ - Encoder: 60 bars
â”‚ - Decoder: 12 bars
â”‚ - Output: 7 quantiles
â”‚ - Loss: QuantileLoss
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Predictions     â”‚
â”‚ - Quantile predictions
â”‚ - Confidence score
â”‚ â†’ Backtest Engine
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. MODEL MÄ°MARÄ°SÄ°

### TFT (Temporal Fusion Transformer)

**Mimari Ã–zellikleri:**
- **Encoder Length**: 60 bar (geÃ§miÅŸ veri)
- **Decoder Length**: 12 bar (gelecek tahmin)
- **Hidden Size**: 128 (HPO ile optimize edilir: [64, 128, 256, 512])
- **Attention Heads**: 4
- **Dropout**: 0.1 (HPO ile optimize edilir: [0.0, 0.5])
- **Task Mode**: 
  - Quantile (default): 7 quantile (0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98)
  - Regression: 1 output (nokta tahmin)
- **Loss**: 
  - QuantileLoss (quantile mode iÃ§in)
  - MAE/RMSE (regression mode iÃ§in)

**Neden Quantile?** 
- Sadece nokta tahmin deÄŸil, belirsizlik (uncertainty) de tahmin edilir
- Risk yÃ¶netimi iÃ§in kritiktir
- Confidence score hesaplanabilir (inter-quantile range)

**Context Features:**
- BTC dominance
- USDT dominance
- Market-wide indicators

### PPO Agent

**Mimari Ã–zellikleri:**
- **Policy**: RecurrentPPO (LSTM-based)
  - LSTM hidden size: 512
  - Temporal dependency handling
  
- **Observation Space**: 
  - TFT confidence (0-1): Model prediction confidence
  - ATR: Volatilite gÃ¶stergesi
  - PnL state: Current profit/loss
  - Position info: Current position, size, leverage

- **Action Space**: Continuous [-1, 1]
  - Action > 0.3 â†’ LONG
  - Action < -0.3 â†’ SHORT
  - -0.3 â‰¤ Action â‰¤ 0.3 â†’ FLAT (Cash)

- **Reward Function**: 
  - Portfolio return (risk-adjusted)
  - Drawdown penalty
  - Transaction cost penalty

- **Hyperparameters**:
  - Learning rate: 3e-4
  - N steps: 4096
  - Batch size: 256
  - N epochs: 10
  - Gamma: 0.99 (discount factor)
  - GAE lambda: 0.95
  - Clip range: 0.2
  - Entropy coefficient: 0.01
  - Value function coefficient: 0.5

---

## 5. TRAINING PIPELINE

### AdÄ±m 1: Preflight Checks (`scripts/preflight.py`)

**Kontroller:**
- âœ… **Environment**: Python version, required packages, CUDA availability
- âœ… **Disk Space**: Minimum 1 GB free space
- âœ… **Data Validation**: 
  - Schema check (required columns)
  - Timestamp validation (sorted, unique)
  - Timeframe spacing validation
  - NaN/Inf detection
- âœ… **Model Forward Pass**: KÃ¼Ã§Ã¼k batch ile model testi

**SonuÃ§**: "OK_TO_TRAIN", "FIXED_AND_OK", veya "BLOCKED"

### AdÄ±m 2: Data Loading (`data/loader_new.py`)

**Ä°ÅŸlemler:**
- Parquet dosyasÄ±ndan yÃ¼kleme
- Date range filtering (config'den)
- Resampling (gerekirse: 15m â†’ 1h â†’ 4h)
- Timestamp sorting

### AdÄ±m 3: Feature Engineering (`features/build_features.py`)

**Ä°ÅŸlemler:**
- Teknik indikatÃ¶rlerin hesaplanmasÄ±:
  - RSI (period: 14)
  - MACD (fast: 12, slow: 26, signal: 9)
  - ATR (period: 14)
  - Bollinger Bands (period: 20, std: 2.0)
  - Volume MA (period: 20)
- Target: Forward return (12 bar sonrasÄ±)
  - `target = (future_close - current_close) / current_close`
- NaN/Inf handling
- Warmup period drop (ilk N bar, feature hesaplanamaz)

### AdÄ±m 4: Data Split (`training/train_one.py`)

**Split Stratejisi:**
- **Time-based split** (shuffle YOK - lookahead bias Ã¶nleme)
- Train: 70% (ilk %70)
- Val: 15% (sonraki %15)
- Test: 15% (son %15)

**Neden shuffle yok?** 
- Gelecek verileri kullanarak geÃ§miÅŸi tahmin etmek (lookahead bias) Ã¶nlenir
- GerÃ§ekÃ§i backtest iÃ§in kritik

### AdÄ±m 5: HPO (`hpo/optuna_search.py`)

**Ä°ÅŸlemler:**
- Optuna study oluÅŸturma
- Her trial iÃ§in:
  - Hyperparameter suggestion
  - Model oluÅŸturma
  - KÄ±sa training (5 epoch)
  - Validation loss hesaplama
  - Pruning check (kÃ¶tÃ¼ trial'larÄ± erken durdur)
- Best params seÃ§imi
- SQLite database'e kaydetme

**Search Space:**
- `lr`: 1e-5 to 5e-3 (log scale)
- `batch_size`: [32, 64, 128]
- `dropout`: 0.0 to 0.5
- `hidden_size`: [64, 128, 256, 512]
- `weight_decay`: 1e-8 to 1e-2 (log scale)

### AdÄ±m 6: Final Training (`training/train_final.py`)

**Ä°ÅŸlemler:**
- Best params ile model oluÅŸturma
- Train+Val birleÅŸtirilerek final training
- Full epochs (config'den)
- Early stopping (patience: 5)
- Model checkpointing
- Best model kaydetme

### AdÄ±m 7: Evaluation (`evaluation/metrics.py`)

**Ä°ÅŸlemler:**
- Test set Ã¼zerinde prediction
- Metrikler hesaplama (MAE, RMSE, MAPE, RÂ²)
- Backtest Ã§alÄ±ÅŸtÄ±rma
- Backtest metrikleri (Sharpe, Sortino, Max DD, Win Rate)

---

## 6. Ã–NEMLÄ° DOSYALAR VE NE ZAMAN DEÄžÄ°ÅžTÄ°RÄ°LMELÄ°

### âœ… DeÄŸiÅŸtirmeniz Gerekenler:

1. **`config/train.yaml`**: 
   - `date_range`: Veri tarih aralÄ±ÄŸÄ± (start, end)
   - `batch_size`: GPU memory'ye gÃ¶re ayarlayÄ±n
   - `epochs`: Training sÃ¼resi (daha fazla epoch = daha uzun training)
   - `hpo.n_trials`: HPO trial sayÄ±sÄ± (daha fazla trial = daha iyi params, ama daha uzun sÃ¼re)
   - `device`: "cuda" veya "cpu"
   - `mixed_precision`: "bf16" (RTX 5070/5080 iÃ§in Ã¶nerilir), "fp16", veya "fp32"

2. **`config/features.yaml`**:
   - `feature_params`: Feature parametreleri (RSI period, MACD fast/slow, etc.)
   - Yeni feature eklemek iÃ§in `build_features.py`'yi deÄŸiÅŸtirin

3. **`hpo/optuna_search.py`**:
   - Search space'i geniÅŸletmek iÃ§in (Ã¶r: `batch_size: [64, 128, 256, 512]`)
   - Objective function'Ä± deÄŸiÅŸtirmek iÃ§in (Ã¶r: Sharpe ratio maximize)

### âŒ DeÄŸiÅŸtirmemeniz Gerekenler (Ä°Ã§ Mimari):

- **`utils/model_contracts.py`**: Model contract validation (kritik)
  - Output/target/loss uyumunu garanti eder
  - DeÄŸiÅŸtirirseniz model Ã§alÄ±ÅŸmayabilir

- **`training/trainer.py`**: Training wrapper (OOM/NaN handling)
  - Robust error handling iÃ§erir
  - DeÄŸiÅŸtirirseniz training stability bozulabilir

- **`data/validators.py`**: Data validation logic
  - Veri kalitesini garanti eder
  - DeÄŸiÅŸtirirseniz data quality sorunlarÄ± olabilir

---

## 7. MÃœHENDÄ°SLÄ°K PERSPEKTÄ°FÄ°NDEN Ã–NERÄ°LER

### Deep Learning Ä°yileÅŸtirmeleri:

1. **Attention Mechanism**: 
   - TFT'deki attention head sayÄ±sÄ±nÄ± artÄ±rÄ±n (4 â†’ 8)
   - Multi-head attention daha iyi pattern recognition saÄŸlar

2. **Ensemble**: 
   - 3 timeframe'i birleÅŸtiren ensemble model kullanÄ±n (`tft_ensemble.py`)
   - Ensemble prediction: Weighted average veya voting

3. **Feature Engineering**: 
   - Daha fazla teknik indikatÃ¶r (Stochastic, ADX, CCI, etc.)
   - Market microstructure features (order book imbalance, etc.)
   - Sentiment features (social media, news, etc.)

4. **Loss Function**: 
   - Quantile loss yerine custom loss (risk-adjusted return)
   - Asymmetric loss (downside risk'a daha fazla aÄŸÄ±rlÄ±k)

5. **Architecture**: 
   - Transformer encoder yerine Graph Neural Network (coin correlation)
   - Temporal Convolutional Network (TCN) alternatifi

### Sistem MÃ¼hendisliÄŸi:

1. **Caching**: 
   - Feature cache mekanizmasÄ± zaten var (`data/cache.py`)
   - Model checkpointing zaten var
   - Distributed training iÃ§in DDP (Distributed Data Parallel) eklenebilir

2. **Parallelization**: 
   - HPO sequential (CPU safety iÃ§in)
   - Training parallel (limited workers)
   - GPU memory optimization (gradient checkpointing)

3. **Error Handling**: 
   - OOM, NaN handling zaten mevcut
   - Retry mechanism eklenebilir
   - Graceful degradation (GPU yoksa CPU)

4. **Reproducibility**: 
   - Seed management zaten var (`utils/seed.py`)
   - Experiment tracking (MLflow, Weights & Biases) eklenebilir

5. **Monitoring**: 
   - Training metrics logging (TensorBoard)
   - Model performance tracking
   - Alert system (model degradation)

---

## 8. Ã‡ALIÅžTIRMA KOMUTLARI

### Ana Pipeline (Ã–nerilen)

```bash
# BTC pipeline - 3 timeframe (15m, 1h, 4h)
python scripts/run_btc_pipeline.py \
    --config config/train.yaml \
    --hpo_trials 100 \
    --max_parallel_training 2

# Parametreler:
# --config: Config dosyasÄ± yolu
# --hpo_trials: HPO trial sayÄ±sÄ± (her timeframe iÃ§in)
# --hpo_timeout: HPO timeout (dakika, optional)
# --max_parallel_training: Paralel training worker sayÄ±sÄ± (CPU safety iÃ§in 2 Ã¶nerilir)
```

### Veri Ä°ndirme

```bash
# 90 gÃ¼nlÃ¼k veri indir
python scripts/download_data.py --days 90

# Parametreler:
# --days: Ä°ndirilecek gÃ¼n sayÄ±sÄ± (default: 90)
```

### Environment KontrolÃ¼

```bash
# PyTorch/CUDA kurulum kontrolÃ¼
python scripts/verify_env.py

# Ã‡Ä±ktÄ±:
# - PyTorch version
# - CUDA availability
# - GPU device name
# - Compute capability
```

### Optuna Dashboard

```bash
# HPO sonuÃ§larÄ±nÄ± gÃ¶rselleÅŸtirmek iÃ§in
optuna-dashboard artifacts/{run_id}/{timeframe}/optuna.db

# Ã–rnek:
optuna-dashboard artifacts/20251229_193144/15m/optuna.db

# Browser'da aÃ§Ä±lÄ±r: http://localhost:8080
```

### Preflight Check

```bash
# Pre-training validation
python scripts/preflight.py \
    --config config/train.yaml \
    --run_id 20251229_193144 \
    --timeframe 15m
```

---

## 9. SORUN GÄ°DERME Ä°Ã‡Ä°N BAKILACAK YERLER

### 1. Data Yoksa

**Semptom**: `FileNotFoundError: Data file not found: data\raw\BTC_USDT_15m.parquet`

**Ã‡Ã¶zÃ¼m**:
```bash
# Veri indir
python scripts/download_data.py --days 90

# Kontrol et
ls data/raw/
```

**Dosya**: `data/raw/` klasÃ¶rÃ¼nÃ¼ kontrol edin

### 2. CUDA HatasÄ±

**Semptom**: `CUDA requested but not available`

**Ã‡Ã¶zÃ¼m**:
```bash
# Environment kontrolÃ¼
python scripts/verify_env.py

# PyTorch CUDA versiyonunu kontrol et
python -c "import torch; print(torch.__version__); print(torch.cuda.is_available())"

# CUDA 12.8 iÃ§in PyTorch kurulumu (RTX 5070/5080)
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```

**Dosya**: `scripts/verify_env.py`

### 3. OOM (Out of Memory) HatasÄ±

**Semptom**: `RuntimeError: CUDA out of memory`

**Ã‡Ã¶zÃ¼m**:
- `config/train.yaml`'da `batch_size`'Ä± dÃ¼ÅŸÃ¼rÃ¼n:
  ```yaml
  batch_size:
    "15m": 128  # 256'dan 128'e dÃ¼ÅŸÃ¼r
    "1h": 128
    "4h": 128
  ```
- Mixed precision kullanÄ±n: `mixed_precision: "bf16"`
- Gradient checkpointing ekleyin (ileride)

**Dosya**: `config/train.yaml`, `training/trainer.py`

### 4. NaN Loss

**Semptom**: `Loss is not finite: nan`

**Ã‡Ã¶zÃ¼m**:
- Learning rate'i dÃ¼ÅŸÃ¼rÃ¼n
- Gradient clipping'i artÄ±rÄ±n: `grad_clip: 1.0` â†’ `grad_clip: 0.5`
- Feature scaling kontrol edin (normalization)

**Dosya**: `training/trainer.py`, `config/train.yaml`

### 5. Preflight Blocked

**Semptom**: `Preflight BLOCKED for 15m`

**Ã‡Ã¶zÃ¼m**:
- Log dosyasÄ±nÄ± kontrol edin: `artifacts/{run_id}/run.log`
- Preflight errors'Ä± kontrol edin:
  ```bash
  python scripts/preflight.py --config config/train.yaml --run_id {run_id} --timeframe 15m
  ```
- Data validation errors'Ä± dÃ¼zeltin

**Dosya**: `scripts/preflight.py`, `artifacts/{run_id}/run.log`

### 6. HPO Ã‡ok YavaÅŸ

**Semptom**: HPO trial'larÄ± Ã§ok uzun sÃ¼rÃ¼yor

**Ã‡Ã¶zÃ¼m**:
- Trial sayÄ±sÄ±nÄ± azaltÄ±n: `hpo.n_trials: 50` (100'den 50'ye)
- Timeout ekleyin: `hpo.timeout_minutes: 120`
- Epoch sayÄ±sÄ±nÄ± azaltÄ±n (HPO iÃ§in): `hpo/optuna_search.py`'de `epochs=5` â†’ `epochs=3`

**Dosya**: `config/train.yaml`, `hpo/optuna_search.py`

### 7. Model Contract Violation

**Semptom**: `CONTRACT VIOLATION: ...`

**Ã‡Ã¶zÃ¼m**:
- `utils/model_contracts.py`'yi kontrol edin
- Task mode'u kontrol edin: `config/train.yaml` â†’ `task.mode`
- Output size ve loss function uyumunu kontrol edin

**Dosya**: `utils/model_contracts.py`, `config/train.yaml`

---

## 10. SONUÃ‡

Bu proje, **production-ready** bir trading bot sistemidir. TÃ¼m bileÅŸenler modÃ¼ler, test edilebilir ve geniÅŸletilebilir ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

### Deep Learning KÄ±smÄ±na MÃ¼hendislik Bilgilerinizi Eklemek Ä°Ã§in:

1. **Model Architecture**: 
   - `models/tft.py`: TFT model mimarisi
   - `models/ppo.py`: PPO agent mimarisi
   - Attention mechanism, LSTM layers, etc.

2. **Feature Engineering**: 
   - `features/build_features.py`: Yeni feature'lar ekleyin
   - Market microstructure features
   - Sentiment features

3. **Loss Functions**: 
   - `utils/model_contracts.py`: Loss computation logic
   - `training/trainer.py`: Training loop
   - Custom loss functions (risk-adjusted return)

4. **Hyperparameter Search**: 
   - `hpo/optuna_search.py`: Search space, objective function
   - Multi-objective optimization (return + Sharpe)

### Ã–nemli Notlar:

- **Model Contract**: `utils/model_contracts.py` dosyasÄ± kritiktir. Model deÄŸiÅŸikliklerinde mutlaka kontrol edin.
- **Data Validation**: `data/validators.py` veri kalitesini garanti eder. DeÄŸiÅŸtirmeyin.
- **Training Wrapper**: `training/trainer.py` robust error handling iÃ§erir. DeÄŸiÅŸtirmeyin.
- **Config Files**: TÃ¼m parametreler YAML'da. Kod deÄŸiÅŸikliÄŸi olmadan ayarlar yapÄ±labilir.

### Ä°letiÅŸim ve Destek:

- Log dosyalarÄ±: `artifacts/{run_id}/run.log`
- Optuna dashboard: `optuna-dashboard artifacts/{run_id}/{timeframe}/optuna.db`
- Preflight check: `python scripts/preflight.py --config config/train.yaml --run_id {run_id} --timeframe {timeframe}`

---

**Son GÃ¼ncelleme**: 2025-01-01
**Versiyon**: 1.0.0

